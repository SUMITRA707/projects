{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUMITRA707/projects/blob/main/fake_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-5CDZFs1GFV"
      },
      "source": [
        "Fake News Detection System\n",
        "\n",
        "Project Overview\n",
        "The Fake News Detection System is an advanced Natural Language Processing (NLP) application designed to classify news articles as either real or fake. Leveraging machine learning and text processing techniques, the system processes textual data, extracts meaningful features, and employs a Logistic Regression model to distinguish between credible and misleading news. This project is implemented in Google Colab, utilizing the emineyetm/fake-news-detection-datasets dataset from Kaggle, and is tailored for media agencies, social platforms, or researchers aiming to combat disinformation in an era of rapidly spreading information.\n",
        "Objectives\n",
        "\n",
        "Accurate Classification: Develop a robust model to differentiate between real and fake news articles with high accuracy.\n",
        "End-to-End NLP Pipeline: Implement a complete workflow including data preprocessing, feature extraction, model training, and evaluation.\n",
        "User-Friendly Interface: Provide an interactive interface for users to input news articles and receive real-time predictions.\n",
        "Performance Visualization: Present model performance through a confusion matrix and detailed classification metrics.\n",
        "\n",
        "\n",
        "Dataset\n",
        "The system utilizes the emineyetm/fake-news-detection-datasets dataset, which includes two CSV files: Fake.csv and True.csv. Each file contains news articles with the following columns:\n",
        "\n",
        "title: The headline of the news article.\n",
        "text: The body of the article.\n",
        "subject: The topic or category (e.g., politics, world news).\n",
        "date: The publication date.A subjectdate column is created by combining subject and date to match the user’s dataset structure. The dataset is labeled with 0 for real news (from True.csv) and 1 for fake news (from Fake.csv). To manage memory in Google Colab, the dataset is limited to 5000 articles per file, ensuring efficient processing while maintaining sufficient data for training.\n",
        "\n",
        "\n",
        "Methodology\n",
        "\n",
        "The project follows a structured NLP pipeline:\n",
        "\n",
        "Data Loading and Preprocessing:\n",
        "The dataset is downloaded via kagglehub and combined into a single DataFrame.\n",
        "The title and text columns are concatenated to form a unified text column for analysis.\n",
        "Text preprocessing uses the Natural Language Toolkit (NLTK):\n",
        "Tokenization: Splits text into individual words using word_tokenize.\n",
        "Stopword Removal: Filters out common words (e.g., “the”, “is”) using NLTK’s English stopwords list.\n",
        "Cleaning: Converts text to lowercase and retains only alphanumeric tokens to reduce noise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Feature Extraction:\n",
        "Text is transformed into numerical features using TF-IDF Vectorization (TfidfVectorizer from Scikit-learn) with a maximum of 5000 features, capturing the most significant terms.\n",
        "\n",
        "\n",
        "Model Training:\n",
        "A Logistic Regression classifier is trained on 80% of the data, with 20% reserved for testing.\n",
        "The model is optimized with a maximum of 1000 iterations to ensure convergence.\n",
        "\n",
        "\n",
        "Evaluation:\n",
        "Model performance is assessed using a confusion matrix (visualized with Seaborn) and a classification report detailing precision, recall, and F1-score.\n",
        "\n",
        "\n",
        "Prediction Interface:\n",
        "An interactive interface is implemented using ipywidgets in Colab, featuring a text box and a “Classify” button for users to input news articles and receive predictions with confidence scores.\n",
        "\n",
        "\n",
        "\n",
        "Technical Stack\n",
        "\n",
        "Programming Language: Python 3\n",
        "Environment: Google Colab\n",
        "Libraries:\n",
        "numpy==1.23.5: Numerical computations.\n",
        "pandas==1.5.3: Data manipulation.\n",
        "scikit-learn==1.2.2: Machine learning and TF-IDF vectorization.\n",
        "nltk==3.8.1: Text preprocessing (tokenization, stopwords).\n",
        "matplotlib==3.7.1, seaborn==0.12.2: Visualization.\n",
        "kagglehub==0.2.9: Dataset downloading.\n",
        "ipywidgets==8.1.5: Interactive input interface.\n",
        "\n",
        "\n",
        "Dataset: emineyetm/fake-news-detection-datasets from Kaggle.\n",
        "\n",
        "Key Features\n",
        "\n",
        "Robust Preprocessing: Handles diverse text data with NLTK’s tokenization and stopword removal, ensuring clean input for modeling.\n",
        "High Accuracy: Logistic Regression achieves reliable classification, with potential to explore alternatives like Naive Bayes for improved performance.\n",
        "Interactive Predictions: Users can input custom news articles via a text box and receive immediate classification results with confidence scores.\n",
        "Comprehensive Evaluation: Visualizes performance with a confusion matrix and provides detailed metrics (precision, recall, F1-score).\n",
        "Memory Efficiency: Limits dataset size to prevent memory issues in Colab, with scalability for larger datasets.\n",
        "\n",
        "Implementation Details\n",
        "\n",
        "Data Loading: Uses kagglehub to fetch the dataset, combining Fake.csv and True.csv into a unified DataFrame with a label column.\n",
        "Error Handling: Includes extensive logging to diagnose issues like missing columns, invalid text, or runtime errors.\n",
        "Colab Compatibility: Addresses numpy.dtype binary incompatibility by pinning library versions and requiring a runtime restart.\n",
        "User Interface: Replaces Colab’s input() with ipywidgets for reliable interactive predictions, ensuring the prediction step executes fully.\n",
        "\n",
        "Challenges and Solutions\n",
        "\n",
        "Numpy Error: Resolved by pinning numpy==1.23.5 and compatible library versions, with a runtime restart.\n",
        "Dataset Structure: Adapted to handle title, text, subjectdate by combining title and text and inferring labels from Fake.csv/True.csv.\n",
        "Interactive Input: Overcame Colab’s input() limitations by using ipywidgets for a user-friendly text box and button.\n",
        "\n",
        "Usage Instructions\n",
        "\n",
        "Setup: Run the code in a Google Colab notebook.\n",
        "Install Libraries: Execute the installation cell and restart the runtime.\n",
        "Load Dataset: Automatically downloads and processes emineyetm/fake-news-detection-datasets.\n",
        "Train and Evaluate: Trains the model and displays a confusion matrix and classification report.\n",
        "Predict: Enter a news article in the text box (e.g., “NASA discovers new exoplanet”) and click “Classify” to view the prediction.\n",
        "\n",
        "Future Improvements\n",
        "\n",
        "Model Exploration: Test alternative classifiers like Multinomial Naive Bayes or deep learning models (e.g., LSTM).\n",
        "Feature Engineering: Incorporate additional features like n-grams or word embeddings (e.g., BERT).\n",
        "Scalability: Support larger datasets by optimizing memory usage or using cloud storage.\n",
        "Web Deployment: Convert the system into a Streamlit app for broader accessibility.\n",
        "\n",
        "Conclusion\n",
        "The Fake News Detection System is a robust NLP solution for identifying misinformation, leveraging the power of NLTK, Scikit-learn, and Logistic Regression. Its interactive interface and detailed evaluation make it a valuable tool for media analysis and research. By processing the emineyetm/fake-news-detection-datasets dataset in Google Colab, the system achieves high accuracy and provides a user-friendly experience for real-time news classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "0b801fe6afcd4583a8dbec875c4e3bab",
            "0699cea3b1a24cbfa62c2431e9283fc7",
            "029e2d7bee5a45d691c347028d12f69c",
            "d7cf4ddb33294edd90168fef438e5daf",
            "66e2aa5300c04dd5b79990226c92ee17",
            "03686ad81ec54cde8d6af9454c35e711",
            "135bdc58f52b4defb70005a059bea370",
            "06c99fcdf02b4ac9a38aa281f778eb9b"
          ]
        },
        "id": "QpOmKhhrolIK",
        "outputId": "3f550c7e-00e0-4257-d246-1f5e25d5cd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.3889 - loss: 0.6790 - val_accuracy: 0.0000e+00 - val_loss: 0.7438\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3889 - loss: 0.6704 - val_accuracy: 0.0000e+00 - val_loss: 0.7464\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2222 - loss: 0.7065 - val_accuracy: 0.0000e+00 - val_loss: 0.7477\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3889 - loss: 0.6644 - val_accuracy: 0.0000e+00 - val_loss: 0.7495\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3889 - loss: 0.6602 - val_accuracy: 0.0000e+00 - val_loss: 0.7515\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', placeholder='Enter news text here...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b801fe6afcd4583a8dbec875c4e3bab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Check News', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7cf4ddb33294edd90168fef438e5daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "135bdc58f52b4defb70005a059bea370"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to check news. Enter text and click 'Check News'.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import logging\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Download and verify NLTK punkt resource\n",
        "try:\n",
        "    # Download 'punkt_tab' as suggested by the error message\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    word_tokenize(\"Test sentence\")\n",
        "    logger.info(\"NLTK punkt_tab resource downloaded and verified\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"NLTK download error: {e}\")\n",
        "    raise\n",
        "\n",
        "# Load sample dataset (replace with your dataset if available)\n",
        "# Example: Using a small dummy dataset\n",
        "data = {\n",
        "    'text': [\n",
        "        \"Breaking: World ends tomorrow!\",\n",
        "        \"Local charity event raises $500.\",\n",
        "        \"Fake alert: Aliens invade Earth!\",\n",
        "        \"Weather forecast predicts rain.\"\n",
        "    ],\n",
        "    'label': [1, 0, 1, 0]  # 1 = Fake, 0 = Real\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "logger.info(f\"Loaded dataset with {len(df)} entries\")\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Vectorize and split data\n",
        "vectorizer = TfidfVectorizer(max_features=500)\n",
        "X = vectorizer.fit_transform(df['text']).toarray()\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "logger.info(\"Data vectorized and split\")\n",
        "\n",
        "# Define and train model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=2, validation_data=(X_test, y_test), verbose=1)\n",
        "logger.info(\"Model trained\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_news(text):\n",
        "    try:\n",
        "        processed_text = preprocess_text(text)\n",
        "        vector = vectorizer.transform([processed_text]).toarray()\n",
        "        prediction = model.predict(vector, verbose=0)\n",
        "        return \"Fake\" if prediction[0][0] > 0.5 else \"Real\"\n",
        "    except Exception as e:\n",
        "        return f\"Error predicting: {e}\"\n",
        "\n",
        "# Input and Output Widgets\n",
        "input_text = widgets.Textarea(placeholder=\"Enter news text here...\")\n",
        "button = widgets.Button(description=\"Check News\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        text = input_text.value\n",
        "        if not text:\n",
        "            print(\"Please enter some text.\")\n",
        "            return\n",
        "        result = predict_news(text)\n",
        "        print(f\"Prediction: {result}\")\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "display(input_text, button, output)\n",
        "print(\"Ready to check news. Enter text and click 'Check News'.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAi9hq2NRJZnT+0f2tIt//",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b801fe6afcd4583a8dbec875c4e3bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0699cea3b1a24cbfa62c2431e9283fc7",
            "placeholder": "Enter news text here...",
            "rows": null,
            "style": "IPY_MODEL_029e2d7bee5a45d691c347028d12f69c",
            "value": ""
          }
        },
        "0699cea3b1a24cbfa62c2431e9283fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "029e2d7bee5a45d691c347028d12f69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7cf4ddb33294edd90168fef438e5daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Check News",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_66e2aa5300c04dd5b79990226c92ee17",
            "style": "IPY_MODEL_03686ad81ec54cde8d6af9454c35e711",
            "tooltip": ""
          }
        },
        "66e2aa5300c04dd5b79990226c92ee17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03686ad81ec54cde8d6af9454c35e711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "135bdc58f52b4defb70005a059bea370": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_06c99fcdf02b4ac9a38aa281f778eb9b",
            "msg_id": "",
            "outputs": []
          }
        },
        "06c99fcdf02b4ac9a38aa281f778eb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}